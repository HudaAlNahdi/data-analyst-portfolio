{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U44-qabUQIg"
      },
      "source": [
        "# Web Scraping for Data Collection using Python\n",
        "\n",
        "This notebook demonstrates how web scraping techniques are used to extract structured data from a website for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8d9bBZ5UQIy"
      },
      "source": [
        "## Process Overview\n",
        "- Send HTTP request to retrieve webpage content\n",
        "- Parse HTML using BeautifulSoup\n",
        "- Extract relevant elements\n",
        "- Convert extracted data into structured format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "id": "B5Cxj3gkUQI0"
      },
      "outputs": [],
      "source": [
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvGNuNxdUQI7",
        "outputId": "36d2882b-4894-4e34-f30a-ad39ed15882f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.12/dist-packages (1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.12/dist-packages (from html5lib) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from html5lib) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "!pip install html5lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "460L6hEOUQI-"
      },
      "outputs": [],
      "source": [
        "data = requests.get(url).text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "id": "FPC-QMAxUQJA"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(data, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koRLPXW0UQJC",
        "outputId": "e9e37b36-ea5d-477f-8a9b-b030fab0782b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Language , Average Annual Salary',\n",
              " 'Python , 114383',\n",
              " 'Java , 101013',\n",
              " 'R , 92037',\n",
              " 'Javascript , 110981',\n",
              " 'Swift , 130801',\n",
              " 'C++ , 113865',\n",
              " 'C# , 88726',\n",
              " 'PHP , 84727',\n",
              " 'SQL , 84793',\n",
              " 'Go , 94082']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "table = soup.find('table')\n",
        "popular_languages = []\n",
        "\n",
        "for row in table.find_all('tr'):\n",
        "    cols = row.find_all('td')\n",
        "    language = cols[1].get_text(strip=True)\n",
        "    avg_salary = cols[3].get_text(strip=True)\n",
        "    popular_languages.append(str(language) + ' , ' + str(avg_salary).replace('$', '').replace(',',''))\n",
        "\n",
        "\n",
        "popular_languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oEERNagUQJF",
        "outputId": "4d323a56-a296-4204-a18e-188609c34fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(popular_languages)\n",
        "df.to_csv('2.b-popular-languages (Collected from WepScraping).csv', header=False, index= False)\n",
        "print('SAVED')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}